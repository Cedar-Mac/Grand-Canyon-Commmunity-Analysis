---
title: "entropy_ratios"
output:
  pdf_document: default
  html_notebook: default
editor_options:
  chunk_output_type: console
---

## Load packages and folder_rename function
```{r include=FALSE}
# Load packages
packages <- c('JAMP', 'here', 'tidyverse', 'vegan', 'Biostrings')
lapply(packages, library, character.only = T)
source("JAMP_folder_rename.R")
```

## Compare mean entropy scores
A few different ideas here:
  1. Corrected entropy score a la Antich:
      for each method calculate the mean entropy for each codon position in a sequence ->
      average across all sequences for that method ->
      calculate final entropy score of the sequence by weighted average of the average mean entropy score.
      formula -- sum(i=3) entropy(i) * 3 / (entropy(1) + entropy(2) + entropy(3))
  2. First position entropy score:
      For each method take the mean entropy for a single codon position (likely position 1) ->
      average across all sequences for that method, use that as final entropy value for the method
  3. Entropy ratio a la Weitemier:
      For each method find the average of the mean entropy scores for position 2 and 3 across sequences ->
      calculate the ratio of average mean entropy score of position 2 and 3.
  4. Information content:
      Information content takes the maximum possible entropy value and subtracts the observed entropy value.
  5. Something complicated:
      Something to do with the entropy scores of individual sequences. 
      Maybe flag method if any individual sequence has an outrageous entropy score.
      Maybe develop a filter for haplotype sequences based on the entropy score.
```{r taxreturn entropy}
# Going with option 3, entropy ratio. Taxreturn method.
haplo_seqs <- list.files(path = ".", pattern = ".*_haplo_sequ_by_OTU.txt", recursive = TRUE, full.names = TRUE) %>% 
  grep("_data", ., value = TRUE)

entropy_ratio_by_method <- data.frame(method=character(0), entropy_ratio=double(0))

start_time <- Sys.time()

for (file in haplo_seqs) {
  haplo_seq_StringSet <- readDNAStringSet(file, format = "fasta", use.names = TRUE)
  entropy_scores <- taxreturn::codon_entropy(haplo_seq_StringSet, genetic_code = "SGC4", codon_filter = TRUE, method = "ML")
    #method "ML" is the maximum likelihood. Calculates Shannon Entropy (H) using frequencies of bases.
    #maximum entropy is 1.3863 nats (ln) for a completely random distribution of base frequency (expected for pos3).
    #genetic code "SGC4" is the invertebrate mitochondrial reference genome.
  pos1_mean_entropy <- lapply(1:length(entropy_scores), function(x) entropy_scores[[x]][[1]]) %>% unlist() %>% mean()
  pos2_info <- log(4) - pos1_mean_entropy
  pos2_mean_entropy <- lapply(1:length(entropy_scores), function(x) entropy_scores[[x]][[2]]) %>% unlist() %>% mean()
  pos2_info <- log(4) - pos2_mean_entropy
  pos3_mean_entropy <- lapply(1:length(entropy_scores), function(x) entropy_scores[[x]][[3]]) %>% unlist() %>% mean()
  pos3_info <- log(4) - pos3_mean_entropy
  entropy_ratio <- pos3_mean_entropy / pos1_mean_entropy
  entropy_ratio_by_method <- add_row(entropy_ratio_by_method, method = substr(file, 23, nchar(file) - 52), entropy_ratio = entropy_ratio)
}

end_time <- Sys.time() # end timer once for loop is completed

end_time - start_time

# Add column for maxee and alpha value
entropy_ratio_by_method$maxee <- parse_number(unlist(strsplit(entropy_ratio_by_method$method, "alpha")))[seq(1, 32, 2)] 
entropy_ratio_by_method$maxee[entropy_ratio_by_method$maxee == 0] <- 0.5
entropy_ratio_by_method$alpha <- parse_number(unlist(strsplit(entropy_ratio_by_method$method, "alpha")))[seq(2, 32, 2)] 

# Graph entropy ratio vs. alpha value for each ee.
entropy_ratio_by_method %>% 
  ggplot((aes(x=alpha, y=entropy_ratio, group=factor(maxee), color=factor(maxee)))) +
    geom_line() +
    scale_color_discrete() +
    ggtitle("Codon Entropy Ratio from Taxreturn (corrected)") +
    ylab("Entropy Ratio (P2/P3)")
```

71-72 sequences are being removed because they contain stop codons. These are clearly not true haplotypes.
Additionally one sequence is always being reverse complimented, this is probably not supposed to be here after filtering and denoising. My guess is chimeral DNA that somehow got past the denoising process of JAMP.
Current ratio is greater than 1 which would mean that position 3 has a lower entropy value/is more predictable. That goes against standard pattern of codon entropy. Potentially this is an issue with alignment and the codon_entropy function. Alternatively, since the entropy is empirical and based on observed counts in the sequences, it may be that the CO1 gene sequence being used is too short (142 bp). This could throw off base counts at each codon position. I believe the alignment issue could be very likely because the entropy value for position 1 would fit for position 3, and the entropy value of position 3 would fit with what we know about position 2 being highly conserved. I will test for this with multiple sequence alignment to a reference CO1 gene.

## Verify entropy scores myself
I ran a Blastx search on a random sequence. It appears a +2 shift in the reading frame is necessary to align with protein synthesis, therefore the first base in our sequences are actually the 3rd. I'm not sure if the taxreturn::codon_entropy function is taking that into account. If it is not taking the shift into account then the output is actually much closer to what is expected. We will verify here. Between sequence base entropy.
```{r between-sequence entropy}
haplo_seqs <- list.files(path = ".", pattern = ".*_haplo_sequ_by_OTU.txt", recursive = TRUE, full.names = TRUE) %>% 
  grep("_data", ., value = TRUE)

my_entropy_ratios <- data.frame(method=character(0), entropy_ratio=double(0))

for (file in haplo_seqs) {
  # read in file
  haplo_seq_StringSet <- readDNAStringSet(file, format = "fasta", use.names = TRUE)
 
   # create probability table of each base at each position.
  position_probability_matrix <- consensusMatrix(haplo_seq_StringSet, as.prob = TRUE, shift = 2, baseOnly = TRUE)
  
  # motif logo of the consensus matrix.
  ggseqlogo::ggseqlogo(position_probability_matrix)
 
   # calculate entropy at each position using Shannon entropy formula with natural logarithm (to match the nats unit above)
  position_entropy_vector <- apply(position_probability_matrix, 2, function(prob) -sum(prob * log(prob), na.rm = TRUE))
 
   # reshape so there are three columns, one for each codon position. Fill the first two zero's as NA and rename columns.
  codon_position_entropy_matrix <- matrix(position_entropy_vector, ncol = 3, byrow = TRUE)
  codon_position_entropy_matrix[codon_position_entropy_matrix==0] <- NA
  colnames(codon_position_entropy_matrix) <- c("pos_1", "pos_2", "pos_3")
  
  # calculate mean entropy of each codon position.
  pos_1_mean <- colMeans(codon_position_entropy_matrix, na.rm = TRUE)[1]
  pos_2_mean <- colMeans(codon_position_entropy_matrix, na.rm = TRUE)[2]
  pos_3_mean <- colMeans(codon_position_entropy_matrix, na.rm = TRUE)[3]
  
  # ratio of most conserved position (position 2) and the most variable position (position 3)
  ratio <- pos_2_mean / pos_3_mean
  
  # add the method results to the data frame and repeat.
  my_entropy_ratios <- add_row(my_entropy_ratios, method = substr(file, 23, nchar(file) - 52), entropy_ratio = ratio)
}

# Add column for maxee and alpha value
my_entropy_ratios$maxee <- parse_number(unlist(strsplit(my_entropy_ratios$method, "alpha")))[seq(1, 32, 2)] 
my_entropy_ratios$maxee[my_entropy_ratios$maxee == 0] <- 0.5
my_entropy_ratios$alpha <- parse_number(unlist(strsplit(my_entropy_ratios$method, "alpha")))[seq(2, 32, 2)] 

# Graph entropy ratio vs. alpha value for each ee.
my_entropy_ratios %>% 
  ggplot((aes(x=alpha, y=entropy_ratio, group=factor(maxee), color=factor(maxee)))) +
    geom_line() +
    scale_color_discrete() +
    ggtitle("Codon Entropy Ratio Comparing Between Sequences") +
    ylab("Entropy Ratio (P2/P3)")
```

There seems to be an issue where the codon_entropy is calculating the entropy within a sequence, i.e. counting all the occurrences of 'A' at position 1 of each codon. Above, I calculated the entropy at each position in the sequence by comparing haplotype sequences. I'll try it the AlexPiper method below.

```{r within-sequence entropy}
haplo_seqs <- list.files(path = ".", pattern = ".*_haplo_sequ_by_OTU.txt", recursive = TRUE, full.names = TRUE) %>% 
  grep("_data", ., value = TRUE)

codon_entropy_table <- data.frame(pos1=double(0), pos2=double(0), pos3=double(0))
codon_entropy_ratios <- data.frame(method=character(0), entropy_ratio=double(0))

start_time <- Sys.time()

for (file in haplo_seqs) {
  # read in file
  haplo_seq_StringSet <- readDNAStringSet(file, format = "fasta", use.names = TRUE)
  
  
  for (sequence in seq_along(haplo_seq_StringSet)) {
    # Turn into vector of characters to select all bases in codon position 1, 2 and 3.
    shifted_seq <- haplo_seq_StringSet[sequence] %>% as.character() %>% 
    paste("--", ., sep = '') %>% 
    str_split("") %>% 
    unlist() 
    
    # Take every third base starting at positions 1, 2, and 3 to get the list of bases at each position
    pos_1_bases <- shifted_seq[seq(1, length(shifted_seq), 3)]
    pos_2_bases <- shifted_seq[seq(2, length(shifted_seq), 3)]
    pos_3_bases <- shifted_seq[seq(3, length(shifted_seq), 3)]
    
    # Formula for Shannon H Entropy. find the probability of each base with table(pos)[base] / 47. Plug into Entropy formula
    pos_1_entropy <- -sum((table(pos_1_bases)["A"] / 47) * log((table(pos_1_bases)["A"] / 47)) + 
        (table(pos_1_bases)["C"] / 47) * log((table(pos_1_bases)["C"] / 47)) + 
          (table(pos_1_bases)["G"] / 47) * log((table(pos_1_bases)["G"] / 47)) +
          (table(pos_1_bases)["T"] / 47) * log((table(pos_1_bases)["T"] / 47)))

    pos_2_entropy <- -sum((table(pos_2_bases)["A"] / 47) * log((table(pos_2_bases)["A"] / 47)) + 
        (table(pos_2_bases)["C"] / 47) * log((table(pos_2_bases)["C"] / 47)) + 
          (table(pos_2_bases)["G"] / 47) * log((table(pos_2_bases)["G"] / 47)) +
          (table(pos_2_bases)["T"] / 47) * log((table(pos_2_bases)["T"] / 47)))
    
    pos_3_entropy <- -sum((table(pos_3_bases)["A"] / 48) * log((table(pos_3_bases)["A"] / 48)) + 
        (table(pos_3_bases)["C"] / 48) * log((table(pos_3_bases)["C"] / 48)) + 
          (table(pos_3_bases)["G"] / 48) * log((table(pos_3_bases)["G"] / 48)) +
          (table(pos_3_bases)["T"] / 48) * log((table(pos_3_bases)["T"] / 48)))
    codon_entropy_table <- add_row(codon_entropy_table, 
                                   pos1 = pos_1_entropy,
                                   pos2 = pos_2_entropy,
                                   pos3 = pos_3_entropy)
    }

  
  codon_entropy_ratio = mean(codon_entropy_table$pos2) / mean(codon_entropy_table$pos3, na.rm = TRUE)
  
  codon_entropy_ratios <- add_row(codon_entropy_ratios, 
                                  method = substr(file, 23, nchar(file) - 52), 
                                  entropy_ratio = codon_entropy_ratio)
}

end_time <- Sys.time() # end timer once for loop is completed

end_time - start_time

# Add column for maxee and alpha value
codon_entropy_ratios$maxee <- parse_number(unlist(strsplit(codon_entropy_ratios$method, "alpha")))[seq(1, 32, 2)] 
codon_entropy_ratios$maxee[codon_entropy_ratios$maxee == 0] <- 0.5
codon_entropy_ratios$alpha <- parse_number(unlist(strsplit(codon_entropy_ratios$method, "alpha")))[seq(2, 32, 2)] 

# Graph entropy ratio vs. alpha value for each ee.
codon_entropy_ratios %>% 
  ggplot((aes(x=alpha, y=entropy_ratio, group=factor(maxee), color=factor(maxee)))) +
    geom_line() +
    scale_color_discrete() +
    ggtitle("Codon Entropy Ratio Comparing Within Sequence") +
    ylab("Entropy Ratio (P2/P3)")
```

The entropy ratio of codon position 2 and codon position 3 should be less than 1 (codon position 3 is more variable, and therefore has a higher entropy score). At low alpha values we are being very strict, this should remove more variability from position 2 (lower entropy score) while position 3 stays relatively unchanged (already variable). This should result in small ratios at low alpha values. As denoising becomes less strict there will be increased variability at codon 2 compared to codon 3 resulting in higher ratios at higher alpha values. For some reason I do not see that in either manual method. That is the trend supported by Weitmier et al. so I must be doing something wrong? I have double-checked the formulas, so I'm not really sure where this could be happening.
Antich: "In other words, two sequences separated by n differences in third positions are more likely to be naturally-occurring sequences than if the n differences happen to occur in second positions, because position 3 is naturally more variable."